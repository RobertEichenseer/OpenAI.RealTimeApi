{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI - Real Time API with tool calling\n",
    "\n",
    "## Overview\n",
    "\n",
    "The audio file *./assets/audio/QuestionSuperSportChampionship2025.wav* contains the question ***Who has won the Super Sports Championship 2025?*** and will be provided directly to the model instance. Because it's a fictional sport event the model will not be able to answer the question without further grounding information or function/tool calling.\n",
    "\n",
    "## Environment\n",
    "\n",
    "An Azure OpenAI GPT-4 instance (gpt-4o-mini-realtime-preview) will be used in this sample. The necessary connection information is imported from the ***config.env*** file in the [../config/ folder](../config). The provided [Azure CLI Powershell script](../setup/setup.azcli) can be used to create the necessary instance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Azure.AI.OpenAI, 2.2.0-beta.2</span></li><li><span>DotNetEnv, 3.1.1</span></li><li><span>NAudio, 2.2.1</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded...\r\n"
     ]
    }
   ],
   "source": [
    "#r \"nuget: Azure.AI.OpenAI, 2.2.0-beta.2\"\n",
    "#r \"nuget: DotNetEnv, 3.1.1\"\n",
    "#r \"nuget: NAudio, 2.2.1\"\n",
    "\n",
    "using DotNetEnv;\n",
    "using System.IO;\n",
    "using Azure.AI.OpenAI;\n",
    "using OpenAI.RealtimeConversation;\n",
    "using System.ClientModel;\n",
    "using NAudio.Wave;\n",
    "\n",
    "string configurationFile = \"../config/config.env\";\n",
    "\n",
    "Env.Load(configurationFile);\n",
    "\n",
    "string apiKey = Env.GetString(\"RT_OPENAI_APIKEY\");\n",
    "string endpoint = Env.GetString(\"RT_OPENAI_ENDPOINT\");\n",
    "string chatCompletionDeployment = Env.GetString(\"RT_OPENAI_CHATCOMPLETION_DEPLOYMENT\");\n",
    "string assetFolder = \"../assets/\";\n",
    "\n",
    "string audioFile = Path.Join(assetFolder, \"Audio\", \"QuestionSuperSportChampionship2025.wav\");\n",
    "\n",
    "Console.WriteLine($\"Configuration loaded...\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool Definition\n",
    "\n",
    "The `RetrieveSportResultsTool` method defines a `ConversationFunctionTool` named \"*get_sport_event_result*\", which is designed to retrieve the result of a specified sports event. \n",
    "\n",
    "It includes a description explaining its purpose and specifies a JSON schema for its parameters which can be called by the model to achieve the expected outcome.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConversationFunctionTool defined...\r\n"
     ]
    }
   ],
   "source": [
    "#pragma warning disable OPENAI002 \n",
    "\n",
    "static ConversationFunctionTool RetrieveSportResultsTool()\n",
    "{\n",
    "    return new ConversationFunctionTool(\"get_sport_event_result\")\n",
    "    {\n",
    "        Description = \"gets the result of a sport event\",\n",
    "        Parameters = BinaryData.FromString(\"\"\"\n",
    "        {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "            \"event\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The sport event, e.g. Super Bowl\"\n",
    "            }\n",
    "            },\n",
    "            \"required\": [\"event\"]\n",
    "        }\n",
    "        \"\"\")\n",
    "    };\n",
    "}\n",
    "\n",
    "Console.WriteLine($\"ConversationFunctionTool defined...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realtime Conversation Client\n",
    "\n",
    "Azure OpenAI SDK provides an `RealTimeConversationClient` to simplify the interaction with the model's real time API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Realtime conversation client created...\r\n"
     ]
    }
   ],
   "source": [
    "#pragma warning disable OPENAI002\n",
    "\n",
    "ApiKeyCredential azureKeyCredential = new ApiKeyCredential(apiKey);\n",
    "AzureOpenAIClient openAIClient = new AzureOpenAIClient(new Uri(endpoint), azureKeyCredential);\n",
    "RealtimeConversationClient realtimeConversationClient = openAIClient.GetRealtimeConversationClient(chatCompletionDeployment);\n",
    "\n",
    "Console.WriteLine($\"Realtime conversation client created...\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real time conversation session\n",
    "\n",
    "An instance of `ConversationSessionOptions` is used to configure a specific session with the model. It allows providing tools to support the model in it's task by providing existing functions to the `Tools` property.\n",
    "\n",
    "```csharp\n",
    "    ConversationSessionOptions conversationSessionOptions = new ConversationSessionOptions(){\n",
    "        ...,\n",
    "        Tools = {RetrieveSportResultsTool()},\n",
    "        ...\n",
    "    };\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Realtime conversation session configured...\r\n"
     ]
    }
   ],
   "source": [
    "#pragma warning disable OPENAI002\n",
    "\n",
    "string systemPrompt = \"You are an assistant which helps user to find information about sport events.\";\n",
    "\n",
    "RealtimeConversationSession realTimeConversationSession = await realtimeConversationClient.StartConversationSessionAsync();\n",
    "ConversationSessionOptions conversationSessionOptions = new ConversationSessionOptions(){\n",
    "    Instructions = systemPrompt,\n",
    "    Voice = ConversationVoice.Alloy,\n",
    "    Tools = {RetrieveSportResultsTool()},\n",
    "    InputAudioFormat = ConversationAudioFormat.Pcm16,\n",
    "    OutputAudioFormat = ConversationAudioFormat.Pcm16,\n",
    "    InputTranscriptionOptions = new ConversationInputTranscriptionOptions(){\n",
    "        Model = \"whisper-1\",\n",
    "    }\n",
    "};\n",
    "await realTimeConversationSession.ConfigureSessionAsync(conversationSessionOptions); \n",
    "\n",
    "Console.WriteLine($\"Realtime conversation session configured...\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversation input data\n",
    "\n",
    "Within a conversation multi modal input data can be provided. Within this sample text and audio data is provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation session updated with text + audio data...\r\n"
     ]
    }
   ],
   "source": [
    "#pragma warning disable OPENAI002\n",
    "\n",
    "await realTimeConversationSession.AddItemAsync(\n",
    "    ConversationItem.CreateUserMessage(new ConversationContentPart[] {\"Please answer in German!\"})\n",
    ");\n",
    "\n",
    "await realTimeConversationSession.SendInputAudioAsync(new FileStream(audioFile, FileMode.Open, FileAccess.Read));\n",
    "\n",
    "Console.WriteLine($\"Conversation session updated with text + audio data...\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Response\n",
    "\n",
    "The SDK function `RealTimeConversationSession.ReceiveUpdatesAsync()` provides  asynchronous updates of the processing. \n",
    "\n",
    "- `ConversationUpdateKind.ItemStreamingPartAudioDelta`: Audio response from the model. In the simplified sample the audio response is stored in *.wav files.\n",
    "- `ItemStreamingFinishedUpdate.FunctionCallId`: indicates that a tool (function) call is requested by the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool Call requested: get_sport_event_result\n",
      "Model turn generation finished\n",
      "\tAudio update from model written to file: ../assets/Audio\\QuestionSuperSportChampionship2025.response1.wav\n",
      "\tAudio update from model written to file: ../assets/Audio\\QuestionSuperSportChampionship2025.response2.wav\n",
      "\tAudio update from model written to file: ../assets/Audio\\QuestionSuperSportChampionship2025.response3.wav\n",
      "\tAudio update from model written to file: ../assets/Audio\\QuestionSuperSportChampionship2025.response4.wav\n",
      "\tAudio update from model written to file: ../assets/Audio\\QuestionSuperSportChampionship2025.response5.wav\n",
      "\tAudio update from model written to file: ../assets/Audio\\QuestionSuperSportChampionship2025.response6.wav\n",
      "\tAudio update from model written to file: ../assets/Audio\\QuestionSuperSportChampionship2025.response7.wav\n",
      "\tAudio update from model written to file: ../assets/Audio\\QuestionSuperSportChampionship2025.response8.wav\n",
      "\tAudio update from model written to file: ../assets/Audio\\QuestionSuperSportChampionship2025.response9.wav\n",
      "\tAudio update from model written to file: ../assets/Audio\\QuestionSuperSportChampionship2025.response10.wav\n",
      "\tAudio update from model written to file: ../assets/Audio\\QuestionSuperSportChampionship2025.response11.wav\n",
      "\tAudio update from model written to file: ../assets/Audio\\QuestionSuperSportChampionship2025.response12.wav\n",
      "\tAudio update from model written to file: ../assets/Audio\\QuestionSuperSportChampionship2025.response13.wav\n",
      "\tAudio transcript: Die Munich Flying Dolphins haben die Super Sports Championship 2025 gewonnen mit einem Endstand von 21 zu 14.\n",
      "Model turn generation finished\n"
     ]
    }
   ],
   "source": [
    "#pragma warning disable OPENAI002\n",
    "\n",
    "int updateCount = 1;\n",
    "\n",
    "await foreach (ConversationUpdate conversationUpdate in realTimeConversationSession.ReceiveUpdatesAsync())\n",
    "{\n",
    "    if (conversationUpdate is ConversationItemStreamingPartDeltaUpdate conversationItemStreamingPartDeltaUpdate)\n",
    "    {\n",
    "        if (conversationUpdate.Kind == ConversationUpdateKind.ItemStreamingPartAudioDelta) \n",
    "        {                        \n",
    "            Stream? audioUpdateFromModel = conversationItemStreamingPartDeltaUpdate?.AudioBytes.ToStream(); \n",
    "            if (audioUpdateFromModel is not null)\n",
    "            {\n",
    "                // Handle audio response from model (e.g. stream to speaker, save to file, etc.)\n",
    "                // In this example, raw audio response is converted to wav file\n",
    "                string fileName = Path.ChangeExtension(audioFile, $\".response{updateCount++}.wav\");\n",
    "                \n",
    "                WaveFormat waveFormat = new WaveFormat(24000, 16, 1);\n",
    "                using RawSourceWaveStream rawSourceWaveStream = new RawSourceWaveStream(audioUpdateFromModel, waveFormat);\n",
    "                using WaveFileWriter waveFileWriter = new WaveFileWriter(fileName, waveFormat);\n",
    "                rawSourceWaveStream.CopyTo(waveFileWriter);\n",
    "                \n",
    "                Console.WriteLine($\"\\tAudio update from model written to file: {fileName}\");\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if (conversationUpdate is ConversationItemStreamingFinishedUpdate itemStreamingFinishedUpdate)\n",
    "    {\n",
    "        if (itemStreamingFinishedUpdate.FunctionCallId is not null)\n",
    "        {\n",
    "            //Tool call request identified\n",
    "            //Simulate tool call and provide response\n",
    "            Console.WriteLine($\"Tool Call requested: {itemStreamingFinishedUpdate.FunctionName}\");\n",
    "            \n",
    "            //Simulated tool call result\n",
    "            string simulatedToolCallResult = \"Munich Flying Dolphins with a score of 21 to 14\";\n",
    "\n",
    "            ConversationItem functionOutputItem = ConversationItem.CreateFunctionCallOutput(\n",
    "                callId: itemStreamingFinishedUpdate.FunctionCallId,\n",
    "                output: simulatedToolCallResult\n",
    "            );\n",
    "\n",
    "            await realTimeConversationSession.AddItemAsync(functionOutputItem);\n",
    "        }\n",
    "        else if (itemStreamingFinishedUpdate.MessageContentParts?.Count > 0)\n",
    "        {\n",
    "            foreach (ConversationContentPart contentPart in itemStreamingFinishedUpdate.MessageContentParts)\n",
    "            {\n",
    "                Console.WriteLine($\"Audio transcript: {contentPart.AudioTranscript}\");\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if (conversationUpdate is ConversationResponseFinishedUpdate turnFinishedUpdate)\n",
    "    {\n",
    "        Console.WriteLine($\"Model turn generation finished\");\n",
    "        if (turnFinishedUpdate.CreatedItems.Any(item => item.FunctionName?.Length > 0))\n",
    "        {\n",
    "            await realTimeConversationSession.StartResponseAsync();\n",
    "        }\n",
    "        else\n",
    "        {\n",
    "            break;\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Housekeeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Realtime conversation session disposed...\r\n"
     ]
    }
   ],
   "source": [
    "realTimeConversationSession.Dispose();\n",
    "\n",
    "Console.WriteLine($\"Realtime conversation session disposed...\");\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "languageName": "csharp",
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
